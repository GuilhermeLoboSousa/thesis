{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef655e49-ce62-4fca-8e29-5f51d206bbe8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__ProPythia__\n",
    "\n",
    "This file is a simulation for the antioxidant dataset;\n",
    "\n",
    "I intend to run propythia here so that in the future I can make comparisons with the results obtained with omnia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8911bf3a-9ab9-4712-8df5-95f5232b2561",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "i will do this simulation with the antioxidant data, where the data in unbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1703bfe7-a871-43d3-a6fb-446f3e404c2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:31:54.648011Z",
     "start_time": "2024-05-16T14:31:54.621253Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "396968d6-fe26-4edd-8e9c-ee6b0ad322cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef,f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from propythia.protein.descriptors import ProteinDescritors\n",
    "from propythia.protein.encoding import Encoding\n",
    "from propythia.ml.shallow_ml import ShallowML\n",
    "from propythia.protein.sequence import ReadSequence\n",
    "\n",
    "from propythia.ml.deep_ml import DeepML\n",
    "\n",
    "from propythia.feature_selection import FeatureSelection\n",
    "\n",
    "from propythia.preprocess import Preprocess\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5ffaeaf-8b07-44d7-8ea3-369f0c3ebe01",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Encoding\n",
    "\n",
    "__Note__: 600 is a high value for our dataset, but is the value more mentioned in literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "313ef8cf-0a7d-49df-81b3-cadf4f72819a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# read the data is the first step !! do not forget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6731a58-ae50-4b60-8206-991b5249a05b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "read_seqs = ReadSequence()\n",
    "x_train_bert = read_seqs.par_preprocessing(dataset= x_train_bert, col = 'sequence', B ='N', Z = 'Q', U = 'C', O = 'K', J = 'I', X = '')\n",
    "x_test_bert = read_seqs.par_preprocessing(dataset= x_test_bert, col = 'sequence', B ='N', Z = 'Q', U = 'C', O = 'K', J = 'I', X = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38e35c66-dd12-4707-b437-ed797bda1404",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def pad_and_truncate_sequences(df, seq_col, max_length, padding_value='#'):\n",
    "    \"\"\"\n",
    "    Pad and truncate the protein sequences in a DataFrame to a specific length.\n",
    "\n",
    "    :param df: DataFrame containing the protein sequences.\n",
    "    :param seq_col: Name of the column in df that contains the protein sequences.\n",
    "    :param max_length: The maximum length for all sequences.\n",
    "    :param padding_value: The value to use for padding the sequences.\n",
    "    :return: DataFrame with the padded and truncated sequences.\n",
    "    \"\"\"\n",
    "    def pad_and_truncate(seq):\n",
    "        # Truncate the sequence if it's too long\n",
    "        if len(seq) > max_length:\n",
    "            seq = seq[:max_length]\n",
    "        # Pad the sequence if it's not long enough\n",
    "        elif len(seq) < max_length:\n",
    "            seq += padding_value * (max_length - len(seq))\n",
    "        #seq=\" \".join(seq)\n",
    "        return seq\n",
    "\n",
    "    df['padded_and_truncated_sequence'] = df[seq_col].apply(pad_and_truncate)\n",
    "    return df\n",
    "\n",
    "# Use the function\n",
    "x_train_bert_encode = pad_and_truncate_sequences(x_train_bert, 'sequence', 600)\n",
    "x_test_bert_encode = pad_and_truncate_sequences(x_test_bert, 'sequence', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c9060a6-7f4c-46e0-8ef1-8e6e556358b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "enconde_train_df = Encoding(dataset= x_train_bert_encode ,  col= 'padded_and_truncated_sequence')\n",
    "encode_test_df=Encoding(dataset= x_test_bert_encode ,  col= 'padded_and_truncated_sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T13:31:09.886039Z",
     "start_time": "2024-05-16T13:31:09.867665Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "314b1dc5-df88-4622-9508-a495e558d0dd",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "protbert_train = enconde_train_df.get_protbert()\n",
    "x_train_bert=np.array([x.astype(np.float64) for x in protbert_train['protbert']])\n",
    "\n",
    "protbert_test = encode_test_df.get_protbert()\n",
    "x_test_bert=np.array([x.astype(np.float64) for x in protbert_test['protbert']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ca50cc1-73de-4b6d-84cb-e1ead8d4aab5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Deep Learning\n",
    "\n",
    "The aim is to recreate the deepLearning models implemented in omnia as well as the possibility of optimising hyperparameters by grid search (using a param_grid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ac7eafb-d130-4714-8011-d5b334a35862",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T10:01:43.679202Z",
     "start_time": "2024-05-20T10:01:43.435481Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "862e13fb-3854-4626-b793-7461af774a38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#RNN and propythia\n",
    "def create_rnn_model(rnn_type='LSTM', bidirectional=False, num_rnn_layers=1, hidden_dim=64, num_dense_layers=1, neurons_dense=32, output_dim=1, drop=0.3, activation='relu', last_layers_activations='sigmoid'):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # RNN layers\n",
    "    for i in range(num_rnn_layers):\n",
    "        current_hidden_dim =hidden_dim // (2**i)\n",
    "        if rnn_type == 'LSTM':\n",
    "            rnn_layer = tf.keras.layers.LSTM(current_hidden_dim, return_sequences=(i != num_rnn_layers - 1), activation=activation)\n",
    "        elif rnn_type == 'GRU':\n",
    "            rnn_layer = tf.keras.layers.GRU(current_hidden_dim, return_sequences=(i != num_rnn_layers - 1), activation=activation)\n",
    "        elif rnn_type == 'SimpleRNN':\n",
    "            rnn_layer = tf.keras.layers.SimpleRNN(current_hidden_dim, return_sequences=(i != num_rnn_layers - 1), activation=activation)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid RNN type. Supported types are 'LSTM', 'GRU', and 'SimpleRNN'.\")\n",
    "\n",
    "        if bidirectional:\n",
    "            rnn_layer = tf.keras.layers.Bidirectional(rnn_layer)\n",
    "\n",
    "        model.add(rnn_layer)\n",
    "        model.add(tf.keras.layers.Dropout(drop))\n",
    "\n",
    "    # Dense layers\n",
    "    for i in range(num_dense_layers):\n",
    "        current_neurons_dense = neurons_dense if i == 0 else neurons_dense // (2**i)\n",
    "        model.add(tf.keras.layers.Dense(current_neurons_dense, activation=activation))\n",
    "        model.add(tf.keras.layers.Dropout(drop))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(output_dim, activation=last_layers_activations))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "dl=DeepML(x_train_bert, y_train_bert, x_test_bert, y_test_bert, number_classes=2, problem_type='binary',\n",
    "          x_dval=None, y_dval=None, epochs=100, batch_size=32,\n",
    "          path='', report_name=None, verbose=1,\n",
    "         early_stopping_patience=20, reduce_lr_patience=10, reduce_lr_factor=0.2, reduce_lr_min=0.00001,\n",
    "                 )\n",
    "model = KerasClassifier(build_fn=create_rnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T10:01:45.376744Z",
     "start_time": "2024-05-20T10:01:45.349746Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "085e14c9-f29d-4cef-b335-531ae2d76666",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "\n",
    "def generate_param_grid(num_rnn_layers:list, num_dense_layers:list):\n",
    "    param_grid = {\n",
    "        'rnn_type': ['LSTM', 'GRU', 'SimpleRNN'],\n",
    "        'bidirectional': [True, False],\n",
    "        'num_rnn_layers': num_rnn_layers,\n",
    "        'hidden_dim': [64,128],\n",
    "        'num_dense_layers': num_dense_layers,\n",
    "        'neurons_dense': [64,128],\n",
    "        'output_dim': [1],\n",
    "        'drop': [0.1, 0.3],\n",
    "        'activation': ['relu'],\n",
    "        'last_layers_activations': ['sigmoid']\n",
    "    }\n",
    "    return param_grid\n",
    "num_rnn_layers = [2,3]\n",
    "num_dense_layers = [2,3]\n",
    "param_grid = generate_param_grid(num_rnn_layers, num_dense_layers)\n",
    "best_classifier_rnn=dl.get_opt_params(param_grid,model,scoring=make_scorer(f1_score),optType='randomizedSearch',cv=5,n_iter_search=80)\n",
    "best_classifier_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a84647a-af0f-4de7-8a00-a4187fb074ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open('output_data_rnn_protbert.log', 'w') as f:\n",
    "    f.write(str(captured))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "613914fd-c804-4f38-954b-1107cb42864a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scores, report, cm, cm2=dl.score_testset_classification(best_classifier_rnn)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e9d272e-d45e-4f53-8795-6e3c1dee1028",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y_pred = best_classifier_rnn.predict(dl.x_test)\n",
    "\n",
    "conf_mat = confusion_matrix(dl.y_test, y_pred)\n",
    "\n",
    "dl.conf_matrix_seaborn_table(conf_matrix=conf_mat)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Protbert_data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
