{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4fea307-bbae-462c-b87c-874d2457e03b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__ProPythia__\n",
    "\n",
    "This file is a simulation for the allergenic dataset;\n",
    "\n",
    "I intend to run propythia here so that in the future I can make comparisons with the results obtained with omnia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e486887c-b22a-4cc8-809f-2f1be9495079",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "i will do this simulation with the antioxidant data, where the data in unbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "833a7429-aef3-446f-a332-adf6c3d1dba4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T14:31:54.648011Z",
     "start_time": "2024-05-16T14:31:54.621253Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dce9ba2a-0ce8-46a2-b840-673dfc053847",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef,f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "from propythia.protein.descriptors import ProteinDescritors\n",
    "from propythia.protein.encoding import Encoding\n",
    "from propythia.ml.shallow_ml import ShallowML\n",
    "from propythia.protein.sequence import ReadSequence\n",
    "\n",
    "from propythia.ml.deep_ml import DeepML\n",
    "\n",
    "from propythia.feature_selection import FeatureSelection\n",
    "\n",
    "from propythia.preprocess import Preprocess\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "599469a7-6869-40d2-9880-722c46e6f96a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# nead to read the data : in our case antioxidant and allergenic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a5b161a-5fc7-4cef-a788-e4bf0224cfc0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# read_seqs = ReadSequence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb074356-9976-4612-a797-473ea1c8c25e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "read_seqs = ReadSequence()\n",
    "x_train_tabular = read_seqs.par_preprocessing(dataset= x_train, col = 'sequence', B ='N', Z = 'Q', U = 'C', O = 'K', J = 'I', X = '')\n",
    "x_test_tabular = read_seqs.par_preprocessing(dataset= x_test, col = 'sequence', B ='N', Z = 'Q', U = 'C', O = 'K', J = 'I', X = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0518039-67ee-43be-85e5-f4a271f2f49c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Obtain all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2f15282-37d2-4204-a15f-7065d38ca460",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_train_tabular= ProteinDescritors(dataset= x_train_tabular ,  col= 'sequence')\n",
    "x_test_tabular= ProteinDescritors(dataset= x_test_tabular ,  col= 'sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "362e274b-7dee-48bc-abfd-1f90feadd766",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_train_tabular=x_train_tabular.get_adaptable([17,21,29])\n",
    "x_test_tabular=x_test_tabular.get_adaptable([17,21,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67011c52-b5be-4da5-b45c-0d3439d1ec4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(x_train_tabular.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfe0b3b5-fc5f-45fc-b9ec-bd04bec694f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(x_test_tabular.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57d18d3d-60df-4947-8228-f367b66a5909",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_train_tabular = x_train_tabular.loc[:, ~x_train_tabular.columns.isin([\"sequence\"])]\n",
    "x_test_tabular = x_test_tabular.loc[:, ~x_test_tabular.columns.isin([\"sequence\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b21726e8-7ce6-484e-9fa9-38bc4fe7cc89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5c75e53-0ff8-474a-a0e2-93db573f3b1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_train = MinMaxScaler()\n",
    "\n",
    "x_train_tabular_scale = scaler_train.fit_transform(x_train_tabular)\n",
    "\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "x_test_tabular_scale = scaler_test.fit_transform(x_test_tabular)\n",
    "\n",
    "x_train_tabular = pd.DataFrame(x_train_tabular_scale, columns=x_train_tabular.columns)\n",
    "x_test_tabular = pd.DataFrame(x_test_tabular_scale, columns=x_test_tabular.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96044bb6-da6c-42c9-b751-6d61ec201e0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('train_x_tabular', x_train_tabular.shape)\n",
    "print('test_x_tabular', x_test_tabular.shape)\n",
    "print('train_y_tabular', y_train_tabular.shape)\n",
    "print('test_y_tabular', y_test_tabular.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84810619-9c47-417c-a3eb-54fe664abaea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_train_tabular.to_csv('x_train_tabular.csv', index=False)  # Salvar o conjunto de treino de características\n",
    "\n",
    "x_test_tabular.to_csv('x_test_tabular.csv', index=False)    # Salvar o conjunto de teste de características\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f024f08-cbe3-4eaa-be96-54a7dda0d48f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ShallowML\n",
    "\n",
    "is only for the descriptores features because the tabular format of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e504363b-ab6c-4a77-8d39-078f0562da83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "def train_multiple_models(X_train, X_test, y_train, y_test,model_names=['svc', 'linear_svc', 'rf', 'gboosting','knn', 'sgd', 'lr', 'nn']):\n",
    "    \"\"\"\n",
    "    Train multiple models and return the results in a DataFrame.\n",
    "    :param model_names: List with the names of the models to train.\n",
    "    :param X_train: Training set features.\n",
    "    :param X_test: Test set features.\n",
    "    :param y_train: Training set labels.\n",
    "    :param y_test: Test set labels.\n",
    "    :param X: DataFrame with the features.\n",
    "    :return: DataFrame with the results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    ml = ShallowML(X_train, X_test, y_train, y_test, report_name=None, columns_names=None)\n",
    "    for model_name in model_names:\n",
    "        if model_name == 'svc':\n",
    "            model_params = {'clf__C':[0.01, 1.0,10], 'clf__kernel': ['rbf','linear'], 'clf__gamma': ['auto', 'scale'], 'clf__class_weight': [None,'balanced']}\n",
    "        elif model_name == 'linear_svc':\n",
    "            model_params={'clf__C':[0.01, 1.0,10], 'clf__penalty': ['l2'], 'clf__class_weight': [None,'balanced']}\n",
    "        elif model_name == 'rf':\n",
    "            model_params = {'clf__n_estimators': [10,100,500], 'clf__max_features': [ 'sqrt', 'log2'],'clf__criterion':['gini','entropy'] , 'clf__class_weight': [None,'balanced']}\n",
    "        elif model_name == 'gboosting':\n",
    "            model_params = {'clf__n_estimators': [10, 100, 500], 'clf__max_depth': [1, 3, 5, 10],'clf__max_features': [0.6, 0.9],'clf__learning_rate':[0.1,1]}\n",
    "        elif model_name == 'knn':\n",
    "            model_params = {'clf__n_neighbors': [2,5,10,15],'clf__weights':['uniform', 'distance'], 'clf__leaf_size': [15, 30, 60]}\n",
    "        elif model_name == 'sgd':\n",
    "            model_params = {'clf__loss': ['hinge', 'log', 'modified_huber', 'perceptron'],'clf__alpha': [0.00001, 0.0001, 0.001, 0.01],'clf__early_stopping': [True],'clf__validation_fraction': [0.2],'clf__n_iter_no_change': [5,10],'clf__class_weight':[None,'balanced'] }\n",
    "        elif model_name== 'lr':\n",
    "            model_params = {'clf__C': [0.01, 0.1, 1.0, 10.0], 'clf__solver': ['liblinear', 'lbfgs', 'sag'], 'clf__class_weight': [None,'balanced']}\n",
    "        elif model_name== 'nn':\n",
    "            model_params = {'clf__hidden_layer_sizes':[(50,),(100,),(200,)],'clf__activation': ['logistic', 'tanh', 'relu'],'clf__solver':['adam','sgd'],'clf__alpha': [0.00001, 0.0001, 0.001],'clf__learning_rate_init': [0.0001, 0.001, 0.01]}\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} not implemented.\")\n",
    "        # Call the function train best model to train the model\n",
    "        best_classifier = ml.train_best_model(model_name, score =make_scorer(f1_score), optType='randomizedSearch',param_grid=model_params,cv=5,n_iter=50)\n",
    "        scores, report, cm, cm2 = ml.score_testset(best_classifier)\n",
    "        with open(f'scores_allergenic_data_shallow_{model_name}.txt', 'w') as f:\n",
    "            for metric, value in scores.items():\n",
    "                f.write(f\"{metric}: {value}\\n\")\n",
    "        \n",
    "        y_pred = best_classifier.predict(ml.x_test)\n",
    "\n",
    "        conf_mat = confusion_matrix(ml.y_test, y_pred)\n",
    "\n",
    "        np.savetxt(f'confusion_matrix_allergenic_data_shallow_{model_name}.csv', conf_mat, delimiter=\",\")\n",
    "        joblib.dump(best_classifier, f'best_classifier_data_tabular_shallow_{model_name}.h5')        \n",
    "\n",
    "        results.append({\n",
    "            'model_name': model_name,\n",
    "            'best_params': best_classifier,\n",
    "            'scores': scores\n",
    "        })\n",
    "    \n",
    "    results_df=pd.DataFrame(results)\n",
    "        \n",
    "    return results_df,best_classifier\n",
    "results_df = train_multiple_models(x_train_tabular, x_test_tabular, y_train_tabular, y_test_tabular, model_names=['svc', 'linear_svc', 'rf', 'gboosting','knn', 'sgd', 'lr', 'nn'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d473adcf-64bc-4d38-865d-3f05e5acf12c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eff27ce6-d3d4-4327-96bc-d65fb07c9bdb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "label_counts = y_test_tabular['label'].value_counts()  # Substitua 'label_column_name' pelo nome da coluna de rótulos, caso necessário\n",
    "\n",
    "print(\"Contagem de rótulos no y_test:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1aac5e2c-788d-4bd2-aebf-266808dff696",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#autoencodermlp simultaneously and propythia\n",
    "def create_autoencoder_mlp_model(latent_dim=12, num_layers=1, input_dim=100,neurons_per_layer=64, num_layers_class=1, neurons_mlp=32, num_classes=2, drop=0.3, activation=\"relu\", last_layers_activations=\"sigmoid\"):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Encoder layers\n",
    "    model.add(tf.keras.layers.Dense(input_dim, activation=activation))\n",
    "    model.add(tf.keras.layers.Dropout(drop))\n",
    "    for i in range(num_layers):\n",
    "        current_neurons_per_layer= neurons_per_layer // (2**i)\n",
    "        print(current_neurons_per_layer)\n",
    "        model.add(tf.keras.layers.Dense(current_neurons_per_layer, activation=activation))\n",
    "        model.add(tf.keras.layers.Dropout(drop))\n",
    "    model.add(tf.keras.layers.Dense(latent_dim, activation=activation))\n",
    "    model.add(tf.keras.layers.Dropout(drop))\n",
    "    print(current_neurons_per_layer)\n",
    "    # Decoder layers\n",
    "    for i in reversed(range(num_layers)):\n",
    "        current_neurons_per_layer= current_neurons_per_layer if i == 0 else current_neurons_per_layer *2\n",
    "        print(current_neurons_per_layer)\n",
    "        model.add(tf.keras.layers.Dense(current_neurons_per_layer, activation=activation))\n",
    "        model.add(tf.keras.layers.Dropout(drop))\n",
    "    model.add(tf.keras.layers.Dense(input_dim, activation=activation))\n",
    "\n",
    "    # MLP layers\n",
    "    for i in range(num_layers_class):\n",
    "        current_neurons_mlp= neurons_mlp if i == 0 else neurons_mlp // (2**i)\n",
    "        model.add(tf.keras.layers.Dense(current_neurons_mlp, activation=activation))\n",
    "        model.add(tf.keras.layers.Dropout(drop))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation=last_layers_activations))\n",
    "\n",
    "    model.compile(loss=['mse', 'binary_crossentropy'],loss_weights=[1, 1], optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "dl=DeepML(x_train_tabular, y_train_tabular, x_test_tabular, y_test_tabular, number_classes=2, problem_type='binary',\n",
    "        x_dval=None, y_dval=None, epochs=100, batch_size=32,\n",
    "        path='', report_name=None, verbose=1,\n",
    "        early_stopping_patience=15, reduce_lr_patience=10, reduce_lr_factor=0.2, reduce_lr_min=0.00001,\n",
    "                )\n",
    "model = KerasClassifier(build_fn=create_autoencoder_mlp_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a32d4659-06e1-4f3f-8dd6-efc7654eea63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_param_grid(num_layers:list, num_layers_class:list):\n",
    "    param_grid = {\n",
    "        'latent_dim': [12,6],\n",
    "        'num_layers': num_layers,\n",
    "        'input_dim': [3543],\n",
    "        'neurons_per_layer': [64,128],\n",
    "        'num_layers_class': num_layers_class,\n",
    "        'neurons_mlp': [20,32],\n",
    "        'num_classes': [2],\n",
    "        'drop': [0.1,0.3],\n",
    "        'activation': ['relu'],\n",
    "        'last_layers_activations': ['sigmoid']\n",
    "    }\n",
    "    return param_grid\n",
    "\n",
    "num_layers = [2,3]\n",
    "num_layers_class = [2,3]\n",
    "param_grid = generate_param_grid(num_layers, num_layers_class)\n",
    "\n",
    "best_classifier_autoencoder=dl.get_opt_params(param_grid,model,scoring=make_scorer(f1_score),optType='randomizedSearch',cv=5,n_iter_search=50)\n",
    "dl.save_model(path='best_data_tabular_autoencoder.h5', model=best_classifier_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb9a1ea5-6600-4137-890a-d530ab225628",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scores, report, cm, cm2 = dl.score_testset(best_classifier_autoencoder)\n",
    "with open('scores_data_tabular_autoencoder.txt', 'w') as f:\n",
    "    for metric, value in scores.items():\n",
    "        f.write(f\"{metric}: {value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f3a3cf4-19ec-44b3-bf19-f63031c57542",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y_pred = best_classifier_autoencoder.predict(dl.x_test)\n",
    "\n",
    "conf_mat = confusion_matrix(dl.y_test, y_pred)\n",
    "\n",
    "np.savetxt('confusion_matrix_data_tabular_autoencoder.log.csv', conf_mat, delimiter=\",\")                        \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "tabular_data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
